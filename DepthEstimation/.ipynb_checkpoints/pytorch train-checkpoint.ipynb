{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    # Initialize filters with Gaussian random weights\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif isinstance(m, nn.ConvTranspose2d):\n",
    "        n = m.kernel_size[0] * m.kernel_size[1] * m.in_channels\n",
    "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "\n",
    "class MeanFieldUpdate(nn.Module):\n",
    "    \"\"\"\n",
    "    Meanfield updating for the features and the attention for one pair of features.\n",
    "    bottom_list is a list of observation features derived from the backbone CNN.\n",
    "    update attention map\n",
    "    a_s <-- y_s * (K_s conv y_S)\n",
    "    a_s = b_s conv a_s\n",
    "    a_s <-- Sigmoid(-(a_s + a_s))\n",
    "    update the last scale feature map y_S\n",
    "    y_s <-- K conv y_s\n",
    "    y_S <-- x_S + (a_s * y_s)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bottom_send, bottom_receive, feat_num):\n",
    "        super(MeanFieldUpdate, self).__init__()\n",
    "\n",
    "        self.atten_f = nn.Conv2d(in_channels=bottom_send + bottom_receive, out_channels=feat_num,\n",
    "                                 kernel_size=3, stride=1, padding=1)\n",
    "        self.norm_atten_f = nn.Sigmoid()\n",
    "        self.message_f = nn.Conv2d(in_channels=bottom_send, out_channels=feat_num, kernel_size=3,\n",
    "                                   stride=1, padding=1)\n",
    "        self.Scale = nn.Conv2d(in_channels=feat_num, out_channels=bottom_receive, kernel_size=1, bias=True)\n",
    "\n",
    "    def forward(self, x_s, x_S):\n",
    "        # update attention map\n",
    "        a_s = torch.cat((x_s, x_S), dim=1)\n",
    "        a_s = self.atten_f(a_s)\n",
    "        a_s = self.norm_atten_f(a_s)\n",
    "\n",
    "        # update the last scale feature map y_S\n",
    "        y_s = self.message_f(x_s)\n",
    "        y_S = y_s.mul(a_s)  # production\n",
    "        # scale\n",
    "        y_S = self.Scale(y_S)\n",
    "        y_S = x_S + y_S  # eltwise sum\n",
    "        return y_S\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SAN(nn.Module):\n",
    "    \"\"\"\n",
    "    Based on ResNet-50\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels=3, feat_num=512, feat_width=80, feat_height=24, pretrained=True):\n",
    "        super(SAN, self).__init__()\n",
    "\n",
    "        # backbone Net: ResNet\n",
    "        pretrained_model = torchvision.models.__dict__['resnet{}'.format(50)](pretrained=pretrained)\n",
    "        self.channel = in_channels\n",
    "\n",
    "        self.conv1 = pretrained_model._modules['conv1']\n",
    "        self.bn1 = pretrained_model._modules['bn1']\n",
    "        self.relu = pretrained_model._modules['relu']\n",
    "\n",
    "        self.maxpool = pretrained_model._modules['maxpool']\n",
    "        self.layer1 = pretrained_model._modules['layer1']\n",
    "        self.layer2 = pretrained_model._modules['layer2']\n",
    "        self.layer3 = pretrained_model._modules['layer3']\n",
    "        self.layer4 = pretrained_model._modules['layer4']\n",
    "\n",
    "        # generating multi-scale features with the same dimension\n",
    "        # in paper,  type = 'gaussian'\n",
    "        self.res4f_dec_1 = nn.ConvTranspose2d(1024, feat_num, kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "        self.res4f_dec_1_relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # in paper,  type = 'gaussian'\n",
    "        self.res5c_dec_1 = nn.ConvTranspose2d(2048, feat_num, kernel_size=8, stride=4, padding=2)\n",
    "        self.res5c_dec_1_relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.res4f_dec = nn.UpsamplingBilinear2d(size=(feat_height, feat_width))\n",
    "        self.res3d_dec = nn.UpsamplingBilinear2d(size=(feat_height, feat_width))\n",
    "        self.res5c_dec = nn.UpsamplingBilinear2d(size=(feat_height, feat_width))\n",
    "\n",
    "        # add deep supervision for three semantic layers\n",
    "        self.prediction_3d = nn.Conv2d(feat_num, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "        self.prediction_4f = nn.Conv2d(feat_num, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "        self.prediction_5c = nn.Conv2d(feat_num, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # the first meanfield updating\n",
    "        self.meanFieldUpdate1_1 = MeanFieldUpdate(feat_num, feat_num, feat_num)\n",
    "        self.meanFieldUpdate1_2 = MeanFieldUpdate(feat_num, feat_num, feat_num)\n",
    "        self.meanFieldUpdate1_3 = MeanFieldUpdate(feat_num, feat_num, feat_num)\n",
    "\n",
    "        # the second meanfield updating\n",
    "        self.meanFieldUpdate2_1 = MeanFieldUpdate(feat_num, feat_num, feat_num)\n",
    "        self.meanFieldUpdate2_2 = MeanFieldUpdate(feat_num, feat_num, feat_num)\n",
    "        self.meanFieldUpdate2_3 = MeanFieldUpdate(feat_num, feat_num, feat_num)\n",
    "\n",
    "        # the third meanfield updating\n",
    "        self.meanFieldUpdate3_1 = MeanFieldUpdate(feat_num, feat_num, feat_num)\n",
    "        self.meanFieldUpdate3_2 = MeanFieldUpdate(feat_num, feat_num, feat_num)\n",
    "        self.meanFieldUpdate3_3 = MeanFieldUpdate(feat_num, feat_num, feat_num)\n",
    "\n",
    "        # the fourth meanfield updating\n",
    "        self.meanFieldUpdate4_1 = MeanFieldUpdate(feat_num, feat_num, feat_num)\n",
    "        self.meanFieldUpdate4_2 = MeanFieldUpdate(feat_num, feat_num, feat_num)\n",
    "        self.meanFieldUpdate4_3 = MeanFieldUpdate(feat_num, feat_num, feat_num)\n",
    "\n",
    "        # the fifth meanfield updating\n",
    "        self.meanFieldUpdate5_1 = MeanFieldUpdate(feat_num, feat_num, feat_num)\n",
    "        self.meanFieldUpdate5_2 = MeanFieldUpdate(feat_num, feat_num, feat_num)\n",
    "        self.meanFieldUpdate5_3 = MeanFieldUpdate(feat_num, feat_num, feat_num)\n",
    "\n",
    "        # produce the output\n",
    "        self.pred_1 = nn.ConvTranspose2d(feat_num, feat_num // 2, kernel_size=4, stride=2, padding=1)\n",
    "        self.pred_1_relu = nn.ReLU(inplace=True)\n",
    "        self.pred_2 = nn.ConvTranspose2d(feat_num // 2, feat_num // 4, kernel_size=4, stride=2, padding=1)\n",
    "        self.pred_2_relu = nn.ReLU(inplace=True)\n",
    "        self.pred_3 = nn.Conv2d(feat_num // 4, 1, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # weights init\n",
    "        self.res4f_dec_1.apply(weights_init)\n",
    "        self.res5c_dec_1.apply(weights_init)\n",
    "        self.prediction_3d.apply(weights_init)\n",
    "        self.prediction_4f.apply(weights_init)\n",
    "        self.prediction_5c.apply(weights_init)\n",
    "\n",
    "        self.meanFieldUpdate1_1.apply(weights_init)\n",
    "        self.meanFieldUpdate1_2.apply(weights_init)\n",
    "        self.meanFieldUpdate1_3.apply(weights_init)\n",
    "\n",
    "        self.meanFieldUpdate2_1.apply(weights_init)\n",
    "        self.meanFieldUpdate2_2.apply(weights_init)\n",
    "        self.meanFieldUpdate2_3.apply(weights_init)\n",
    "\n",
    "        self.meanFieldUpdate3_1.apply(weights_init)\n",
    "        self.meanFieldUpdate3_2.apply(weights_init)\n",
    "        self.meanFieldUpdate3_3.apply(weights_init)\n",
    "\n",
    "        self.meanFieldUpdate4_1.apply(weights_init)\n",
    "        self.meanFieldUpdate4_2.apply(weights_init)\n",
    "        self.meanFieldUpdate4_3.apply(weights_init)\n",
    "\n",
    "        self.meanFieldUpdate5_1.apply(weights_init)\n",
    "        self.meanFieldUpdate5_2.apply(weights_init)\n",
    "        self.meanFieldUpdate5_3.apply(weights_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        res3d = x\n",
    "        x = self.layer3(x)\n",
    "        res4f = x\n",
    "        x = self.layer4(x)\n",
    "        res5c = x\n",
    "\n",
    "        # generate multi-scale features with the same dimension,\n",
    "        res4f_1 = self.res4f_dec_1(res4f)  # 1024 --> 512\n",
    "        res4f_1 = self.res4f_dec_1_relu(res4f_1)\n",
    "\n",
    "        res5c_1 = self.res5c_dec_1(res5c)  # 1024 --> 512\n",
    "        res4f_1 = self.res5c_dec_1_relu(res5c_1)\n",
    "\n",
    "        res4f = self.res4f_dec(res4f_1)\n",
    "        res3d = self.res3d_dec(res3d)\n",
    "        res5c = self.res5c_dec(res5c_1)\n",
    "\n",
    "        pred_3d = self.prediction_3d(res3d)\n",
    "        pred_4f = self.prediction_4f(res4f)\n",
    "        pred_5c = self.prediction_5c(res5c)\n",
    "\n",
    "        # five meanfield updating\n",
    "        y_S = self.meanFieldUpdate1_1(res3d, res5c)\n",
    "        y_S = self.meanFieldUpdate1_2(res4f, y_S)\n",
    "        y_S = self.meanFieldUpdate1_3(res5c, y_S)\n",
    "\n",
    "        y_S = self.meanFieldUpdate2_1(res3d, y_S)\n",
    "        y_S = self.meanFieldUpdate2_2(res4f, y_S)\n",
    "        y_S = self.meanFieldUpdate2_3(res5c, y_S)\n",
    "\n",
    "        y_S = self.meanFieldUpdate3_1(res3d, y_S)\n",
    "        y_S = self.meanFieldUpdate3_2(res4f, y_S)\n",
    "        y_S = self.meanFieldUpdate3_3(res5c, y_S)\n",
    "\n",
    "        y_S = self.meanFieldUpdate4_1(res3d, y_S)\n",
    "        y_S = self.meanFieldUpdate4_2(res4f, y_S)\n",
    "        y_S = self.meanFieldUpdate4_3(res5c, y_S)\n",
    "\n",
    "        y_S = self.meanFieldUpdate5_1(res3d, y_S)\n",
    "        y_S = self.meanFieldUpdate5_2(res4f, y_S)\n",
    "        y_S = self.meanFieldUpdate5_3(res5c, y_S)\n",
    "\n",
    "        pred = self.pred_1(y_S)\n",
    "        pred = self.pred_1_relu(pred)\n",
    "        pred = self.pred_2(pred)\n",
    "        pred = self.pred_2_relu(pred)\n",
    "        pred = self.pred_3(pred)\n",
    "\n",
    "        pred = nn.functional.interpolate(pred, size=(375,1242), mode='bilinear', align_corners=True)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAN(feat_width=80, feat_height=24)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "trdt=255*np.random.rand(500,3,288,621)\n",
    "tstdt=255*np.random.rand(500,1,288,621)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "torch.Size([500, 3, 288, 621])\n",
      "torch.Size([500, 1, 288, 621])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "#imports necessary to define a neural network \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#ensure you are using GPU.\n",
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\"  \n",
    "\n",
    "device = torch.device(dev)\n",
    "print(device)\n",
    "\n",
    "dtype = torch.cuda.FloatTensor\n",
    "trdttensor=torch.from_numpy(trdt).type(dtype)\n",
    "resultstensor=torch.from_numpy(tstdt).type(dtype)\n",
    "\n",
    "print(trdttensor.shape)\n",
    "print(resultstensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n",
      "torch.Size([1, 1, 288, 621])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e403f09ee784>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m#forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrdttensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m#compute loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-3263d8d6067f>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m         \u001b[0mres3d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\resnet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[1;31m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# use cumulative moving average\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                     \u001b[0mexponential_average_factor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#trainingloop\n",
    "import torch.optim as optim\n",
    "\n",
    "lr = 0.001\n",
    "batchsize=1\n",
    "\n",
    "batches=len(trdttensor)/batchsize\n",
    "\n",
    "epochs=300\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.Adagrad(model.parameters(), lr)\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    for j in range(int(batches)):\n",
    "        \n",
    "        #forward pass\n",
    "        out=model(trdttensor[j:j+batchsize,:].type(dtype))\n",
    "        print(out.shape)\n",
    "        #compute loss\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = criterion(out,resultstensor[j:j+batchsize].type(dtype))\n",
    "\n",
    "\n",
    "        #backprop loss i.e. find dloss/dparam for each parameter and store.\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        #clip gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        #use optimiser to update\n",
    "        optimizer.step()\n",
    "    print(loss,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(model(trdttensor[0:1,:]).detach().cpu().numpy().reshape(188,621), cmap='magma')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
